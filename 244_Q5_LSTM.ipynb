{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40kNYCEFZdr2",
        "outputId": "d52ebe03-75b3-4e97-86a9-c495b716fe82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.8.0+cu111\n",
            "  Downloading https://download.pytorch.org/whl/cu111/torch-1.8.0%2Bcu111-cp38-cp38-linux_x86_64.whl (1982.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 GB\u001b[0m \u001b[31m868.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.9.0+cu111\n",
            "  Downloading https://download.pytorch.org/whl/cu111/torchvision-0.9.0%2Bcu111-cp38-cp38-linux_x86_64.whl (17.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m79.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio==0.8.0\n",
            "  Downloading torchaudio-0.8.0-cp38-cp38-manylinux1_x86_64.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchtext==0.9.0\n",
            "  Downloading torchtext-0.9.0-cp38-cp38-manylinux1_x86_64.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m100.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torch==1.8.0+cu111) (1.22.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==1.8.0+cu111) (4.5.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.8/dist-packages (from torchvision==0.9.0+cu111) (8.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from torchtext==0.9.0) (4.64.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchtext==0.9.0) (2.25.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.9.0) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.9.0) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.9.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.9.0) (4.0.0)\n",
            "Installing collected packages: torch, torchvision, torchtext, torchaudio\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.13.1+cu116\n",
            "    Uninstalling torch-1.13.1+cu116:\n",
            "      Successfully uninstalled torch-1.13.1+cu116\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.14.1+cu116\n",
            "    Uninstalling torchvision-0.14.1+cu116:\n",
            "      Successfully uninstalled torchvision-0.14.1+cu116\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.14.1\n",
            "    Uninstalling torchtext-0.14.1:\n",
            "      Successfully uninstalled torchtext-0.14.1\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 0.13.1+cu116\n",
            "    Uninstalling torchaudio-0.13.1+cu116:\n",
            "      Successfully uninstalled torchaudio-0.13.1+cu116\n",
            "Successfully installed torch-1.8.0+cu111 torchaudio-0.8.0 torchtext-0.9.0 torchvision-0.9.0+cu111\n"
          ]
        }
      ],
      "source": [
        "!pip install torch==1.8.0+cu111 torchvision==0.9.0+cu111 torchaudio==0.8.0 torchtext==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/bhargaviparanjape/clickbait.git\n",
        "!gzip -d /content/clickbait/dataset/clickbait_data.gz\n",
        "!gzip -d /content/clickbait/dataset/non_clickbait_data.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TAo3atcZe5G8",
        "outputId": "b1056b17-83db-4064-993b-ca713cd82f62"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'clickbait'...\n",
            "remote: Enumerating objects: 104, done.\u001b[K\n",
            "remote: Total 104 (delta 0), reused 0 (delta 0), pack-reused 104\u001b[K\n",
            "Receiving objects: 100% (104/104), 1.54 MiB | 7.65 MiB/s, done.\n",
            "Resolving deltas: 100% (44/44), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "E3BGSZKbhq0u"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1 = open('/content/clickbait/dataset/clickbait_data', 'r')\n",
        "clickbait = f1.readlines()\n",
        "\n",
        "# clickbait\n",
        "clickbait = list(map(lambda x:x.strip(),clickbait))\n",
        "clickbait = list(filter(None, clickbait))\n",
        "\n",
        "cb_df = pd.DataFrame(clickbait, columns = ['text'])\n",
        "cb_df['label'] = 1\n",
        "\n",
        "f2 = open('/content/clickbait/dataset/clickbait_data', 'r')\n",
        "non_clickbait = f2.readlines()\n",
        "\n",
        "non_clickbait = list(map(lambda x:x.strip(),non_clickbait))\n",
        "non_clickbait = list(filter(None, non_clickbait))\n",
        "\n",
        "ncb_df = pd.DataFrame(non_clickbait, columns = ['text'])\n",
        "ncb_df['label'] = 0\n",
        "\n",
        "raw_df = pd.concat([cb_df, ncb_df], ignore_index=True)\n",
        "raw_df.to_csv('raw_data.csv')"
      ],
      "metadata": {
        "id": "BemVfqRIgQS8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "lffFsqA8BbFV"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchtext.legacy import data\n",
        "\n",
        "SEED = 1234\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "TEXT = data.Field(tokenize = 'spacy', tokenizer_language = 'en_core_web_sm')\n",
        "LABEL = data.LabelField(dtype = torch.float)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fields = [('Unnamed: 0', None), ('text', TEXT), (\"label\", LABEL)]\n",
        "\n",
        "raw_data = data.TabularDataset(path=\"raw_data.csv\",format=\"csv\",fields=fields,skip_header=True)"
      ],
      "metadata": {
        "id": "7XJp3kLrge8H"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IatXWViqB3Pi",
        "outputId": "50a0bc46-73d7-42eb-960e-e71c45a970f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training examples: 25598\n",
            "Number of testing examples: 3200\n",
            "Number of testing examples: 3200\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "# train and validation splitting\n",
        "train_data,test_data = raw_data.split(split_ratio=0.80,random_state=random.seed(SEED))\n",
        "print(f'Number of training examples: {len(train_data)}')\n",
        "valid_data, test_data = test_data.split(split_ratio=0.50,random_state=random.seed(SEED))\n",
        "print(f'Number of testing examples: {len(valid_data)}')\n",
        "print(f'Number of testing examples: {len(test_data)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtSufWSGB_bw",
        "outputId": "77254a40-b440-45ee-9b82-12590e6afdbc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique tokens in TEXT vocabulary: 11621\n",
            "Unique tokens in LABEL vocabulary: 2\n",
            "[('You', 8865), ('The', 7980), ('\"', 7919), ('To', 5151), ('A', 4195), ('Your', 4082), ('Of', 3888), (\"'s\", 3706), ('Are', 3223), ('That', 3105), ('In', 3088), ('This', 2842), ('And', 2610), ('Is', 2605), ('On', 2359), ('For', 2265), ('What', 2101), ('Will', 2002), ('-', 1766), ('About', 1708)]\n",
            "['<unk>', '<pad>', 'You', 'The', '\"', 'To', 'A', 'Your', 'Of', \"'s\"]\n",
            "defaultdict(None, {'0': 0, '1': 1})\n"
          ]
        }
      ],
      "source": [
        "MAX_VOCAB_SIZE = 25_000\n",
        "\n",
        "TEXT.build_vocab(train_data, max_size = MAX_VOCAB_SIZE)\n",
        "LABEL.build_vocab(train_data)\n",
        "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n",
        "print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")\n",
        "print(TEXT.vocab.freqs.most_common(20))\n",
        "print(TEXT.vocab.itos[:10])\n",
        "print(LABEL.vocab.stoi)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "s_fT0m_-T8Ew"
      },
      "outputs": [],
      "source": [
        "# Setting up mini batching using dataloaders and collate function\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "\n",
        "def encode_text_pipeline(source):\n",
        "  encoded_text = [TEXT.vocab[word] for word in source]\n",
        "  return torch.tensor(encoded_text, dtype = torch.int64)\n",
        "\n",
        "def encoded_label_pipeline(target):\n",
        "  encoded_label = LABEL.vocab[target]\n",
        "  return torch.tensor(encoded_label, dtype = torch.int64)\n",
        "\n",
        "def pad_function(batch):\n",
        "  x_data = []\n",
        "  y_data = []\n",
        "  x_lengths = []\n",
        "  for i in range(len(batch)):\n",
        "    x_lengths.append(len(batch[i].text))\n",
        "    encoded_text = encode_text_pipeline(batch[i].text)\n",
        "    x_data.append(encoded_text)\n",
        "    encoded_label = encoded_label_pipeline(batch[i].label)\n",
        "    y_data.append(encoded_label)\n",
        "  padded_data = pad_sequence(x_data, batch_first = True, padding_value=0)\n",
        "  return padded_data, torch.tensor(y_data), torch.tensor(x_lengths)\n",
        "\n",
        "\n",
        "def create_loader(dataset):\n",
        "  data_loader = DataLoader(dataset=dataset, batch_size=32, collate_fn = pad_function, drop_last = True)\n",
        "  return data_loader\n",
        "\n",
        "train_loader = create_loader(train_data)\n",
        "valid_loader = create_loader(valid_data)\n",
        "test_loader = create_loader(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufzJ68pF8W9y",
        "outputId": "b40b58cc-5a54-4299-b94b-51a24ffdda6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 17])\n",
            "tensor([[    3,   601,  1067,   221,   289,     2,    60,    71,   213,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0],\n",
            "        [   13,   600,  2109,   787,    15,     3,  2431,   433,     2,    60,\n",
            "            71,  1543,     0,     0,     0,     0,     0],\n",
            "        [   32,     2,    40,    29,    27,   634,   784,    39,  2182,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0],\n",
            "        [   32,     2,    29,    27,   187,   125,    13,     4,  4438,     4,\n",
            "            15,    30,     0,     0,     0,     0,     0],\n",
            "        [  141,    47,  2147,  1558,   282,    88,   283,   532,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0],\n",
            "        [   18,    34,     9,    49,     5,    43,   766,     3,  1604,    53,\n",
            "             6,  1038,  3144,     0,     0,     0,     0],\n",
            "        [   91,    97,    25,    22,    10,    45,  3210,   648,    19,   119,\n",
            "           101,     0,     0,     0,     0,     0,     0],\n",
            "        [   27,  2522,  1127,    10,     2,    41,    16,     7,    84,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0],\n",
            "        [  220,   201,    22,    37,  1848,     5,     4,   630,  3072,     4,\n",
            "             0,     0,     0,     0,     0,     0,     0],\n",
            "        [   48,     3,    47,  3242,    14,  7932,  2923,    16,     4,    11,\n",
            "          2373,     9,   125,     4,     0,     0,     0],\n",
            "        [   91,  1521,   526,     2,   322,    45,   467,  6859,  1686,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0],\n",
            "        [    6,  3143,  1916,    15,     3,   740,  3629,   338,   159,   126,\n",
            "           369,     0,     0,     0,     0,     0,     0],\n",
            "        [  887,   741,   417,    28,   136,    45,    29,    53,     3,   726,\n",
            "             8,    13,   103,     0,     0,     0,     0],\n",
            "        [ 3116,   134,    14,  1916,     5,  7980,     3,  3372,  2738,    35,\n",
            "           378,    34,     9,     6,   217,  3366,     0],\n",
            "        [   72,   560,     6, 10339,    35,   299,    72,   560,   168,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0],\n",
            "        [   46,     9,     7,  2077,   334,   823,  4251,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0],\n",
            "        [  152,  2357,    20, 10305,   422,   299,   357, 10886, 11439,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0],\n",
            "        [ 1220,    19,   121,   129,     2,    59,     6,  1311,     9,  4992,\n",
            "          3522,     0,     0,     0,     0,     0,     0],\n",
            "        [   39,   364,  3576,    65,   747,     3,   206,   295,  5351,   135,\n",
            "             0,     0,     0,     0,     0,     0,     0],\n",
            "        [   95,    98,    11,   198,    65,    26,  5593,  6938,    15,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0],\n",
            "        [  141,    47,  1082,  8229,  1989,   137,    12,    50,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0],\n",
            "        [  511,    23,    21,   675,    25,    11,  3977,     3,   457,    67,\n",
            "             8,    78,  1019,     0,     0,     0,     0],\n",
            "        [   28,    29,    27,  1039,     2,    68,   249,     5,   636,    12,\n",
            "            41,    16,    80,   228,     0,     0,     0],\n",
            "        [  273,    15,   194,   437,    77,     5,   618,     5,     4,    48,\n",
            "            72,   139,    17,   107,    15,     2,     4],\n",
            "        [   66,    23,   340,   268,    11,  9231,  3386,  4103,    67,     8,\n",
            "          6862,     0,     0,     0,     0,     0,     0],\n",
            "        [  193,   109,     2,    37,   211,     3,    58,  4116,     6,  2407,\n",
            "             0,     0,     0,     0,     0,     0,     0],\n",
            "        [    3,  1287,  1529,     8,  4905,     9,   160,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0],\n",
            "        [  148,   350,   615,   201,   342,   195,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0],\n",
            "        [ 1161,   163,   223,   665,  2186,     5,   134,    12,   144,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0],\n",
            "        [  105,   165,     2,  2279,    86,     6,   383,   299,   163,   139,\n",
            "           121,     0,     0,     0,     0,     0,     0],\n",
            "        [  353,   256,   364,   165,    17,     3,  1285,  2273,     2,    29,\n",
            "             0,     0,     0,     0,     0,     0,     0],\n",
            "        [  136,     2,    29,   334, 11073,    58,   894,   823,    73,   116,\n",
            "             0,     0,     0,     0,     0,     0,     0]])\n",
            "torch.Size([32])\n",
            "tensor([0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1,\n",
            "        0, 0, 1, 0, 1, 1, 1, 1])\n",
            "torch.Size([32])\n"
          ]
        }
      ],
      "source": [
        "# for x, y, length in train_loader:\n",
        "#   print(x)\n",
        "#   print(y)\n",
        "#   print(length)\n",
        "#   break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "nI_gFLUXCEdY"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn as nn\n",
        "class LSTM_classifier(nn.Module):\n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
        "        super(LSTM_classifier, self).__init__()\n",
        "        self.n_layers = 1\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=1, dropout=0.4)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, text, x_lengths):\n",
        "      batch_size = text.size(0)\n",
        "      embedded = self.embedding(text)\n",
        "      packed_embeddings = nn.utils.rnn.pack_padded_sequence(embedded, x_lengths, batch_first=True, enforce_sorted=False)\n",
        "      packed_output, (hidden, cell) = self.lstm(packed_embeddings)\n",
        "      output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
        "      prediction = self.fc(torch.mean(output, 0))\n",
        "      return prediction, hidden\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "-lZ2obDVDmEl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "486a85f7-d935-49be-970e-8c640aa45ab0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/rnn.py:60: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        }
      ],
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 64\n",
        "OUTPUT_DIM = 1\n",
        "\n",
        "model = LSTM_classifier(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM ,OUTPUT_DIM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJ6_rLRuK2l7",
        "outputId": "d6c898cc-692e-4648-ab83-14ef9373a10e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has 1,204,661 trainable parameters\n"
          ]
        }
      ],
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "IbufnJzvLAlf"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "I1fHORT8LBOK"
      },
      "outputs": [],
      "source": [
        "criterion = nn.BCEWithLogitsLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "z3gdBHHULC7y"
      },
      "outputs": [],
      "source": [
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "KF2EdETnLEwt"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def binary_accuracy(preds, y):\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    correct = (rounded_preds == y).float()\n",
        "    acc = correct.sum() / len(correct)\n",
        "    f1 = f1_score(rounded_preds.tolist(), y.tolist())\n",
        "    return acc, f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "2o9l76H5LGm9"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "def train(model, iterator, optimizer, criterion):\n",
        "    model.train()\n",
        "    epoch_loss = []\n",
        "    epoch_accuracy = []\n",
        "    epoch_f1 = []\n",
        "    for batch_text, batch_labels, batch_lengths in tqdm(iterator):\n",
        "        batch_size = batch_text.size(0)\n",
        "        optimizer.zero_grad()\n",
        "        batch_labels = batch_labels.to(device)\n",
        "        batch_predictions, hidden = model(batch_text.to(device), batch_lengths)\n",
        "        hidden.detach()\n",
        "        batch_loss = criterion(batch_predictions.squeeze(), batch_labels.squeeze().float())\n",
        "        epoch_loss.append(batch_loss)\n",
        "        batch_loss.backward()\n",
        "        optimizer.step()\n",
        "        batch_acc, batch_f1 = binary_accuracy(batch_predictions.squeeze(), batch_labels.squeeze())\n",
        "        epoch_accuracy.append(batch_acc)\n",
        "        epoch_f1.append(batch_f1)\n",
        "    return sum(epoch_loss)/len(epoch_loss), sum(epoch_accuracy)/len(epoch_accuracy), sum(epoch_f1)/len(epoch_f1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "bBwRhOrzLKSH"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    epoch_loss = []\n",
        "    epoch_accuracy = []\n",
        "    epoch_f1 = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch_text, batch_labels, batch_lengths in tqdm(iterator):\n",
        "            batch_size = batch_text.size(0)\n",
        "            batch_labels = batch_labels.to(device)\n",
        "            batch_predictions, hidden = model(batch_text.to(device), batch_lengths)\n",
        "            hidden.detach()\n",
        "            batch_loss = criterion(batch_predictions.squeeze(), batch_labels.squeeze().float())\n",
        "            epoch_loss.append(batch_loss)\n",
        "            batch_acc, batch_f1 = binary_accuracy(batch_predictions.squeeze(), batch_labels.squeeze())\n",
        "            epoch_accuracy.append(batch_acc)\n",
        "            epoch_f1.append(batch_f1)\n",
        "    return sum(epoch_loss)/len(epoch_loss), sum(epoch_accuracy)/len(epoch_accuracy), sum(epoch_f1)/len(epoch_f1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "FOHkN5P5LMtl"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63EPftxxLOxH",
        "outputId": "ad6e8fb1-dc0a-48ec-b29f-5789b9277417"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 799/799 [00:07<00:00, 111.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:  tensor(0.6933, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy:  tensor(0.4969, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 235.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:  tensor(0.6931, device='cuda:0')\n",
            "Accuracy:  tensor(0.4994, device='cuda:0')\n",
            "Epoch: 01 | Epoch Time: 0m 7s\n",
            "Train Loss: tensor(0.6933, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Train accuracy tensor(0.4969, device='cuda:0')\n",
            "Train F1 0.512309218137563\n",
            "Val Loss: tensor(0.6931, device='cuda:0')\n",
            "Val accuracy tensor(0.4994, device='cuda:0')\n",
            "Val F1 0.5159421368791764\n",
            "Epoch:  1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 799/799 [00:05<00:00, 144.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:  tensor(0.6933, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy:  tensor(0.4973, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 222.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:  tensor(0.6931, device='cuda:0')\n",
            "Accuracy:  tensor(0.4966, device='cuda:0')\n",
            "Epoch: 02 | Epoch Time: 0m 6s\n",
            "Train Loss: tensor(0.6933, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Train accuracy tensor(0.4973, device='cuda:0')\n",
            "Train F1 0.5090896738184288\n",
            "Val Loss: tensor(0.6931, device='cuda:0')\n",
            "Val accuracy tensor(0.4966, device='cuda:0')\n",
            "Val F1 0.5092660606590604\n",
            "Epoch:  2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 799/799 [00:06<00:00, 123.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:  tensor(0.6933, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy:  tensor(0.4978, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 241.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:  tensor(0.6931, device='cuda:0')\n",
            "Accuracy:  tensor(0.4981, device='cuda:0')\n",
            "Epoch: 03 | Epoch Time: 0m 6s\n",
            "Train Loss: tensor(0.6933, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Train accuracy tensor(0.4978, device='cuda:0')\n",
            "Train F1 0.506161728623709\n",
            "Val Loss: tensor(0.6931, device='cuda:0')\n",
            "Val accuracy tensor(0.4981, device='cuda:0')\n",
            "Val F1 0.5071006982286046\n",
            "Epoch:  3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 799/799 [00:05<00:00, 147.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:  tensor(0.6933, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy:  tensor(0.4977, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 235.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:  tensor(0.6931, device='cuda:0')\n",
            "Accuracy:  tensor(0.4994, device='cuda:0')\n",
            "Epoch: 04 | Epoch Time: 0m 5s\n",
            "Train Loss: tensor(0.6933, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Train accuracy tensor(0.4977, device='cuda:0')\n",
            "Train F1 0.5036230993170404\n",
            "Val Loss: tensor(0.6931, device='cuda:0')\n",
            "Val accuracy tensor(0.4994, device='cuda:0')\n",
            "Val F1 0.5065165077375664\n",
            "Epoch:  4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 799/799 [00:06<00:00, 129.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:  tensor(0.6933, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy:  tensor(0.4983, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 167.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:  tensor(0.6931, device='cuda:0')\n",
            "Accuracy:  tensor(0.4994, device='cuda:0')\n",
            "Epoch: 05 | Epoch Time: 0m 6s\n",
            "Train Loss: tensor(0.6933, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Train accuracy tensor(0.4983, device='cuda:0')\n",
            "Train F1 0.5022720210936129\n",
            "Val Loss: tensor(0.6931, device='cuda:0')\n",
            "Val accuracy tensor(0.4994, device='cuda:0')\n",
            "Val F1 0.5052092214237011\n",
            "Epoch:  5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 799/799 [00:05<00:00, 150.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:  tensor(0.6933, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy:  tensor(0.4984, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 244.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:  tensor(0.6931, device='cuda:0')\n",
            "Accuracy:  tensor(0.5003, device='cuda:0')\n",
            "Epoch: 06 | Epoch Time: 0m 5s\n",
            "Train Loss: tensor(0.6933, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Train accuracy tensor(0.4984, device='cuda:0')\n",
            "Train F1 0.5007967461648647\n",
            "Val Loss: tensor(0.6931, device='cuda:0')\n",
            "Val accuracy tensor(0.5003, device='cuda:0')\n",
            "Val F1 0.5044930781584153\n",
            "Epoch:  6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 799/799 [00:05<00:00, 138.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:  tensor(0.6933, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy:  tensor(0.4980, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 168.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:  tensor(0.6931, device='cuda:0')\n",
            "Accuracy:  tensor(0.5009, device='cuda:0')\n",
            "Epoch: 07 | Epoch Time: 0m 6s\n",
            "Train Loss: tensor(0.6933, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Train accuracy tensor(0.4980, device='cuda:0')\n",
            "Train F1 0.4993325909721835\n",
            "Val Loss: tensor(0.6931, device='cuda:0')\n",
            "Val accuracy tensor(0.5009, device='cuda:0')\n",
            "Val F1 0.5038398136047496\n",
            "Epoch:  7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 799/799 [00:05<00:00, 136.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:  tensor(0.6933, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy:  tensor(0.4980, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 242.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:  tensor(0.6931, device='cuda:0')\n",
            "Accuracy:  tensor(0.5019, device='cuda:0')\n",
            "Epoch: 08 | Epoch Time: 0m 6s\n",
            "Train Loss: tensor(0.6933, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Train accuracy tensor(0.4980, device='cuda:0')\n",
            "Train F1 0.4980019513088975\n",
            "Val Loss: tensor(0.6931, device='cuda:0')\n",
            "Val accuracy tensor(0.5019, device='cuda:0')\n",
            "Val F1 0.5035955911930291\n",
            "Epoch:  8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 799/799 [00:05<00:00, 146.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:  tensor(0.6933, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy:  tensor(0.4978, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 181.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:  tensor(0.6931, device='cuda:0')\n",
            "Accuracy:  tensor(0.5012, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "N_EPOCHS = 20\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "tolerance = 2\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    print('Epoch: ', epoch)\n",
        "    start_time = time.time()\n",
        "    train_epoch_loss, train_epoch_accuracy, train_epoch_F1 = train(model, train_loader, optimizer, criterion)\n",
        "    print('Loss: ', train_epoch_loss)\n",
        "    print('Accuracy: ', train_epoch_accuracy)\n",
        "    valid_epoch_loss, valid_epoch_accuracy, valid_epoch_F1 = evaluate(model, valid_loader, criterion)\n",
        "    print('Loss: ', valid_epoch_loss)\n",
        "    print('Accuracy: ', valid_epoch_accuracy)\n",
        "    end_time = time.time()\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_epoch_loss < best_valid_loss:\n",
        "      best_valid_loss = valid_epoch_loss\n",
        "    else:\n",
        "      tolerance -= 1\n",
        "      if tolerance == 0:  \n",
        "        break\n",
        "      \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print('Train Loss:', train_epoch_loss)\n",
        "    print('Train accuracy', train_epoch_accuracy)\n",
        "    print('Train F1', train_epoch_F1)\n",
        "    print('Val Loss:', valid_epoch_loss)\n",
        "    print('Val accuracy', valid_epoch_accuracy)\n",
        "    print('Val F1', valid_epoch_F1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2vQBjeTLTTv",
        "outputId": "38a71c7e-daaf-4961-8d8d-ff2a6315e678"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 185.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss tensor(0.6928, device='cuda:0')\n",
            "Test accuracy tensor(0.5150, device='cuda:0')\n",
            "Test F1 0.5214085798885922\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# model.load_state_dict(torch.load('tut1-model.pt'))\n",
        "\n",
        "test_loss, test_acc, test_f1 = evaluate(model, test_loader, criterion)\n",
        "\n",
        "print('Test Loss',test_loss)\n",
        "print('Test accuracy', test_acc)\n",
        "print('Test F1', test_f1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DWT55qIWSJFu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}