{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40kNYCEFZdr2",
        "outputId": "ba4b5da3-6121-4cdd-ddba-2c0114b37ea6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.8.0+cu111\n",
            "  Downloading https://download.pytorch.org/whl/cu111/torch-1.8.0%2Bcu111-cp38-cp38-linux_x86_64.whl (1982.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 GB\u001b[0m \u001b[31m874.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.9.0+cu111\n",
            "  Downloading https://download.pytorch.org/whl/cu111/torchvision-0.9.0%2Bcu111-cp38-cp38-linux_x86_64.whl (17.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio==0.8.0\n",
            "  Downloading torchaudio-0.8.0-cp38-cp38-manylinux1_x86_64.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchtext==0.9.0\n",
            "  Downloading torchtext-0.9.0-cp38-cp38-manylinux1_x86_64.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m111.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torch==1.8.0+cu111) (1.22.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==1.8.0+cu111) (4.5.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.8/dist-packages (from torchvision==0.9.0+cu111) (8.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from torchtext==0.9.0) (4.64.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchtext==0.9.0) (2.25.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.9.0) (1.26.14)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.9.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.9.0) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.9.0) (4.0.0)\n",
            "Installing collected packages: torch, torchvision, torchtext, torchaudio\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.13.1+cu116\n",
            "    Uninstalling torch-1.13.1+cu116:\n",
            "      Successfully uninstalled torch-1.13.1+cu116\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.14.1+cu116\n",
            "    Uninstalling torchvision-0.14.1+cu116:\n",
            "      Successfully uninstalled torchvision-0.14.1+cu116\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.14.1\n",
            "    Uninstalling torchtext-0.14.1:\n",
            "      Successfully uninstalled torchtext-0.14.1\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 0.13.1+cu116\n",
            "    Uninstalling torchaudio-0.13.1+cu116:\n",
            "      Successfully uninstalled torchaudio-0.13.1+cu116\n",
            "Successfully installed torch-1.8.0+cu111 torchaudio-0.8.0 torchtext-0.9.0 torchvision-0.9.0+cu111\n"
          ]
        }
      ],
      "source": [
        "!pip install torch==1.8.0+cu111 torchvision==0.9.0+cu111 torchaudio==0.8.0 torchtext==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/bhargaviparanjape/clickbait.git\n",
        "!gzip -d /content/clickbait/dataset/clickbait_data.gz\n",
        "!gzip -d /content/clickbait/dataset/non_clickbait_data.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TAo3atcZe5G8",
        "outputId": "8eafcfbf-f256-4954-9097-3a936d87b8f5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'clickbait'...\n",
            "remote: Enumerating objects: 104, done.\u001b[K\n",
            "remote: Total 104 (delta 0), reused 0 (delta 0), pack-reused 104\u001b[K\n",
            "Receiving objects: 100% (104/104), 1.54 MiB | 9.33 MiB/s, done.\n",
            "Resolving deltas: 100% (44/44), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "E3BGSZKbhq0u"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1 = open('/content/clickbait/dataset/clickbait_data', 'r')\n",
        "clickbait = f1.readlines()\n",
        "\n",
        "# clickbait\n",
        "clickbait = list(map(lambda x:x.strip(),clickbait))\n",
        "clickbait = list(filter(None, clickbait))\n",
        "\n",
        "cb_df = pd.DataFrame(clickbait, columns = ['text'])\n",
        "cb_df['label'] = 1\n",
        "\n",
        "f2 = open('/content/clickbait/dataset/non_clickbait_data', 'r')\n",
        "non_clickbait = f2.readlines()\n",
        "\n",
        "non_clickbait = list(map(lambda x:x.strip(),non_clickbait))\n",
        "non_clickbait = list(filter(None, non_clickbait))\n",
        "\n",
        "ncb_df = pd.DataFrame(non_clickbait, columns = ['text'])\n",
        "ncb_df['label'] = 0\n",
        "\n",
        "raw_df = pd.concat([cb_df, ncb_df], ignore_index=True)\n",
        "raw_df.to_csv('raw_data.csv')"
      ],
      "metadata": {
        "id": "BemVfqRIgQS8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Percentage of clickbait data: ', round(len(raw_df[raw_df['label']== 1])/len(raw_df)*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xP1cTXODJXkT",
        "outputId": "d532fe4f-8aaf-4892-8bbb-1c67eae017c1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Percentage of clickbait data:  50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lffFsqA8BbFV"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchtext.legacy import data\n",
        "\n",
        "SEED = 1234\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "TEXT = data.Field(tokenize = 'spacy', tokenizer_language = 'en_core_web_sm')\n",
        "LABEL = data.LabelField(dtype = torch.float)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fields = [('Unnamed: 0', None), ('text', TEXT), (\"label\", LABEL)]\n",
        "\n",
        "raw_data = data.TabularDataset(path=\"raw_data.csv\",format=\"csv\",fields=fields,skip_header=True)"
      ],
      "metadata": {
        "id": "7XJp3kLrge8H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IatXWViqB3Pi",
        "outputId": "bd75315e-2e80-4b0a-e74b-d8a226beff05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training examples: 25600\n",
            "Number of testing examples: 3200\n",
            "Number of testing examples: 3200\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "# train and validation splitting\n",
        "train_data,test_data = raw_data.split(split_ratio=0.80,random_state=random.seed(SEED))\n",
        "print(f'Number of training examples: {len(train_data)}')\n",
        "valid_data, test_data = test_data.split(split_ratio=0.50,random_state=random.seed(SEED))\n",
        "print(f'Number of testing examples: {len(valid_data)}')\n",
        "print(f'Number of testing examples: {len(test_data)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtSufWSGB_bw",
        "outputId": "ead7b964-dad8-48c6-e677-045c327c9387"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique tokens in TEXT vocabulary: 25002\n",
            "Unique tokens in LABEL vocabulary: 2\n",
            "[('You', 4507), ('\"', 4373), ('The', 4127), ('in', 3514), (',', 3273), ('to', 2716), ('To', 2590), (\"'s\", 2450), ('A', 2272), ('of', 2124), ('-', 2092), ('Your', 2074), ('Of', 1936), ('Are', 1713), ('In', 1692), ('Is', 1642), ('That', 1570), ('This', 1447), ('for', 1368), ('And', 1326)]\n",
            "['<unk>', '<pad>', 'You', '\"', 'The', 'in', ',', 'to', 'To', \"'s\"]\n",
            "defaultdict(None, {'1': 0, '0': 1})\n"
          ]
        }
      ],
      "source": [
        "MAX_VOCAB_SIZE = 25_000\n",
        "\n",
        "TEXT.build_vocab(train_data, max_size = MAX_VOCAB_SIZE)\n",
        "LABEL.build_vocab(train_data)\n",
        "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n",
        "print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")\n",
        "print(TEXT.vocab.freqs.most_common(20))\n",
        "print(TEXT.vocab.itos[:10])\n",
        "print(LABEL.vocab.stoi)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TEXT.vocab.stoi['<pad>']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uk9PDhdKoHRk",
        "outputId": "9486b5f7-680d-490a-d4b0-f39ccf798b1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s_fT0m_-T8Ew"
      },
      "outputs": [],
      "source": [
        "# Setting up mini batching using dataloaders and collate function\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "\n",
        "def encode_text_pipeline(source):\n",
        "  encoded_text = [TEXT.vocab[word] for word in source]\n",
        "  return torch.tensor(encoded_text, dtype = torch.int64)\n",
        "\n",
        "def encoded_label_pipeline(target):\n",
        "  encoded_label = LABEL.vocab[target]\n",
        "  return torch.tensor(encoded_label, dtype = torch.int64)\n",
        "\n",
        "def pad_function(batch):\n",
        "  x_data = []\n",
        "  y_data = []\n",
        "  x_lengths = []\n",
        "  for i in range(len(batch)):\n",
        "    x_lengths.append(len(batch[i].text))\n",
        "    encoded_text = encode_text_pipeline(batch[i].text)\n",
        "    x_data.append(encoded_text)\n",
        "    encoded_label = encoded_label_pipeline(batch[i].label)\n",
        "    y_data.append(encoded_label)\n",
        "  padded_data = pad_sequence(x_data, batch_first = True, padding_value=1)\n",
        "  return padded_data, torch.tensor(y_data), torch.tensor(x_lengths)\n",
        "\n",
        "\n",
        "def create_loader(dataset):\n",
        "  data_loader = DataLoader(dataset=dataset, batch_size=32, collate_fn = pad_function, drop_last = True)\n",
        "  return data_loader\n",
        "\n",
        "train_loader = create_loader(train_data)\n",
        "valid_loader = create_loader(valid_data)\n",
        "test_loader = create_loader(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nI_gFLUXCEdY"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn as nn\n",
        "class LSTM_classifier(nn.Module):\n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
        "        super(LSTM_classifier, self).__init__()\n",
        "        self.n_layers = 1\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=1, dropout=0.4)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, text, x_lengths):\n",
        "      batch_size = text.size(0)\n",
        "      embedded = self.embedding(text)\n",
        "      packed_embeddings = nn.utils.rnn.pack_padded_sequence(embedded, x_lengths, batch_first=True, enforce_sorted=False)\n",
        "      packed_output, (hidden, cell) = self.lstm(packed_embeddings)\n",
        "      output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
        "      prediction = self.fc(torch.mean(output, 0))\n",
        "      return prediction, hidden\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-lZ2obDVDmEl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11ff6919-21a8-47dc-a206-699289af8d58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/rnn.py:60: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        }
      ],
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 256\n",
        "HIDDEN_DIM = 128\n",
        "OUTPUT_DIM = 1\n",
        "\n",
        "model = LSTM_classifier(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM ,OUTPUT_DIM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJ6_rLRuK2l7",
        "outputId": "fe25d3b7-e43a-48ba-af4e-ea91d46cb7fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has 6,598,273 trainable parameters\n"
          ]
        }
      ],
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IbufnJzvLAlf"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# optimizer = optim.SGD(model.parameters(), lr=1e-3)\n",
        "optimizer = optim.Adam(model.parameters(), lr = 1e-4 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I1fHORT8LBOK"
      },
      "outputs": [],
      "source": [
        "criterion = nn.BCEWithLogitsLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z3gdBHHULC7y"
      },
      "outputs": [],
      "source": [
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KF2EdETnLEwt"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def binary_accuracy(preds, y):\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    correct = (rounded_preds == y).float()\n",
        "    acc = correct.sum() / len(correct)\n",
        "    f1 = f1_score(rounded_preds.tolist(), y.tolist())\n",
        "    return acc, f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2o9l76H5LGm9"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "def train(model, iterator, optimizer, criterion):\n",
        "    model.train()\n",
        "    epoch_loss = []\n",
        "    epoch_accuracy = []\n",
        "    epoch_f1 = []\n",
        "    for batch_text, batch_labels, batch_lengths in tqdm(iterator):\n",
        "        batch_size = batch_text.size(0)\n",
        "        optimizer.zero_grad()\n",
        "        batch_labels = batch_labels.to(device)\n",
        "        batch_predictions, hidden = model(batch_text.to(device), batch_lengths)\n",
        "        hidden.detach()\n",
        "        batch_loss = criterion(batch_predictions.squeeze(), batch_labels.squeeze().float())\n",
        "        epoch_loss.append(batch_loss)\n",
        "        batch_loss.backward()\n",
        "        optimizer.step()\n",
        "        batch_acc, batch_f1 = binary_accuracy(batch_predictions.squeeze(), batch_labels.squeeze())\n",
        "        epoch_accuracy.append(batch_acc)\n",
        "        epoch_f1.append(batch_f1)\n",
        "    return sum(epoch_loss)/len(epoch_loss), sum(epoch_accuracy)/len(epoch_accuracy), sum(epoch_f1)/len(epoch_f1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bBwRhOrzLKSH"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    epoch_loss = []\n",
        "    epoch_accuracy = []\n",
        "    epoch_f1 = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch_text, batch_labels, batch_lengths in tqdm(iterator):\n",
        "            batch_size = batch_text.size(0)\n",
        "            batch_labels = batch_labels.to(device)\n",
        "            batch_predictions, hidden = model(batch_text.to(device), batch_lengths)\n",
        "            hidden.detach()\n",
        "            batch_loss = criterion(batch_predictions.squeeze(), batch_labels.squeeze().float())\n",
        "            epoch_loss.append(batch_loss)\n",
        "            batch_acc, batch_f1 = binary_accuracy(batch_predictions.squeeze(), batch_labels.squeeze())\n",
        "            epoch_accuracy.append(batch_acc)\n",
        "            epoch_f1.append(batch_f1)\n",
        "    return sum(epoch_loss)/len(epoch_loss), sum(epoch_accuracy)/len(epoch_accuracy), sum(epoch_f1)/len(epoch_f1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FOHkN5P5LMtl"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63EPftxxLOxH",
        "outputId": "5a481868-917c-4500-b968-543b795728c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 800/800 [00:08<00:00, 90.74it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:  tensor(0.3359, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy:  tensor(0.9037, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 223.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:  tensor(0.1770, device='cuda:0')\n",
            "Accuracy:  tensor(0.9547, device='cuda:0')\n",
            "Epoch: 01 | Epoch Time: 0m 9s\n",
            "Train Loss: tensor(0.3359, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Train accuracy tensor(0.9037, device='cuda:0')\n",
            "Train F1 0.8812735720790761\n",
            "Val Loss: tensor(0.1770, device='cuda:0')\n",
            "Val accuracy tensor(0.9547, device='cuda:0')\n",
            "Val F1 0.9559155593711124\n",
            "Epoch:  1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 800/800 [00:09<00:00, 88.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:  tensor(0.1272, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy:  tensor(0.9725, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 208.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:  tensor(0.1477, device='cuda:0')\n",
            "Accuracy:  tensor(0.9600, device='cuda:0')\n",
            "Epoch: 02 | Epoch Time: 0m 9s\n",
            "Train Loss: tensor(0.1272, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Train accuracy tensor(0.9725, device='cuda:0')\n",
            "Train F1 0.9714909861961051\n",
            "Val Loss: tensor(0.1477, device='cuda:0')\n",
            "Val accuracy tensor(0.9600, device='cuda:0')\n",
            "Val F1 0.9616601590853984\n",
            "Epoch:  2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 800/800 [00:08<00:00, 92.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:  tensor(0.0777, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy:  tensor(0.9825, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 139.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:  tensor(0.1457, device='cuda:0')\n",
            "Accuracy:  tensor(0.9625, device='cuda:0')\n",
            "Epoch: 03 | Epoch Time: 0m 9s\n",
            "Train Loss: tensor(0.0777, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Train accuracy tensor(0.9825, device='cuda:0')\n",
            "Train F1 0.9818814750439112\n",
            "Val Loss: tensor(0.1457, device='cuda:0')\n",
            "Val accuracy tensor(0.9625, device='cuda:0')\n",
            "Val F1 0.9636254504259256\n",
            "Epoch:  3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 800/800 [00:08<00:00, 92.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:  tensor(0.0525, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy:  tensor(0.9877, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 202.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:  tensor(0.1560, device='cuda:0')\n",
            "Accuracy:  tensor(0.9609, device='cuda:0')\n",
            "Epoch: 04 | Epoch Time: 0m 9s\n",
            "Train Loss: tensor(0.0525, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Train accuracy tensor(0.9877, device='cuda:0')\n",
            "Train F1 0.9872620721209112\n",
            "Val Loss: tensor(0.1560, device='cuda:0')\n",
            "Val accuracy tensor(0.9609, device='cuda:0')\n",
            "Val F1 0.9619891992449019\n",
            "Epoch:  4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 800/800 [00:09<00:00, 87.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:  tensor(0.0372, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Accuracy:  tensor(0.9909, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 191.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:  tensor(0.1753, device='cuda:0')\n",
            "Accuracy:  tensor(0.9594, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "N_EPOCHS = 10\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "tolerance = 2\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    print('Epoch: ', epoch)\n",
        "    start_time = time.time()\n",
        "    train_epoch_loss, train_epoch_accuracy, train_epoch_F1 = train(model, train_loader, optimizer, criterion)\n",
        "    print('Loss: ', train_epoch_loss)\n",
        "    print('Accuracy: ', train_epoch_accuracy)\n",
        "    valid_epoch_loss, valid_epoch_accuracy, valid_epoch_F1 = evaluate(model, valid_loader, criterion)\n",
        "    print('Loss: ', valid_epoch_loss)\n",
        "    print('Accuracy: ', valid_epoch_accuracy)\n",
        "    end_time = time.time()\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_epoch_loss < best_valid_loss:\n",
        "      best_valid_loss = valid_epoch_loss\n",
        "    else:\n",
        "      tolerance -= 1\n",
        "      if tolerance == 0:  \n",
        "        break\n",
        "      \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print('Train Loss:', train_epoch_loss)\n",
        "    print('Train accuracy', train_epoch_accuracy)\n",
        "    print('Train F1', train_epoch_F1)\n",
        "    print('Val Loss:', valid_epoch_loss)\n",
        "    print('Val accuracy', valid_epoch_accuracy)\n",
        "    print('Val F1', valid_epoch_F1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2vQBjeTLTTv",
        "outputId": "9fc696cf-087f-4f18-8734-dd3776f730c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 216.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss tensor(0.1648, device='cuda:0')\n",
            "Test accuracy tensor(0.9666, device='cuda:0')\n",
            "Test F1 0.9658104132247586\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# model.load_state_dict(torch.load('tut1-model.pt'))\n",
        "\n",
        "test_loss, test_acc, test_f1 = evaluate(model, test_loader, criterion)\n",
        "\n",
        "print('Test Loss',test_loss)\n",
        "print('Test accuracy', test_acc)\n",
        "print('Test F1', test_f1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DWT55qIWSJFu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}